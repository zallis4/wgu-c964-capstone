{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9673926e-ca85-454c-ae3d-c499ff319edb",
   "metadata": {},
   "source": [
    "# C964 Computer Science Capstone\n",
    "## An Analysis of Climate Variables on Corn Yields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27cd747-0cb8-4e88-b769-4326c8975e08",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38938dfa-68e9-447a-bf21-54486140f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "import numpy as numpy\n",
    "import seaborn as seaborn\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.image as display\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# SUPPRESS USER WARNING RELATED TO POLYNOMIAL FEATURE NAMING\n",
    "# CAUSE: No year provided with test data\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4179c4c1-af7a-4151-92cb-1b2c842324ef",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa867c42-01b4-4f52-8990-0364f0b4dde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading and preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "crop_data = pandas.read_csv('corn_bushels_per_acre_by_state.csv')\n",
    "temp_data = pandas.read_csv('average_monthly_temperature_by_state.csv')\n",
    "drought_data = pandas.read_csv('monthly_drought_monitor_by_state.csv')\n",
    "\n",
    "# NORMALIZE FORMATTING AND REMOVE LESS RELEVANT DATA\n",
    "# Change drought data format from string to year and month\n",
    "drought_data['date'] = drought_data['date'].str[2:] # Remove 'd_' prefix\n",
    "drought_data['year'] = drought_data['date'].str[:4].astype(int)\n",
    "drought_data['month'] = drought_data['date'].str[4:6].astype(int)\n",
    "# Capitalize state names and normalize space usage\n",
    "crop_data['state'] = crop_data['state'].str.replace('-', ' ').str.upper().str.strip()\n",
    "temp_data['state'] = temp_data['state'].str.replace('-', ' ').str.upper().str.strip()\n",
    "drought_data['state'] = drought_data['state'].str.replace('-', ' ').str.upper().str.strip()\n",
    "\n",
    "# MERGE TEMPERATURE AND DROUGHT DATA\n",
    "monthly_climate = pandas.merge(\n",
    "    temp_data[['state', 'year', 'month', 'average_temp']],\n",
    "    drought_data[['state', 'year', 'month', 'N0',\n",
    "                  'D0', 'D1', 'D2', 'D3', 'D4',\n",
    "                  'W0', 'W1', 'W2', 'W3', 'W4']],\n",
    "    on = ['state', 'year', 'month'],\n",
    "    how = 'inner'\n",
    ")\n",
    "# Trim data to relevant time frame\n",
    "monthly_climate = monthly_climate[(monthly_climate['year'] >= 1970) & (monthly_climate['year'] <= 2020)]\n",
    "monthly_climate = monthly_climate[(monthly_climate['month'] >= 4) & (monthly_climate['month'] <= 11)]\n",
    "# Save the merged dataset\n",
    "monthly_climate.to_csv('monthly_climate_by_state.csv')\n",
    "\n",
    "# PIVOT MONTHLY CLIMATE DATA FOR EACH CLIMATE FEATURE\n",
    "climate_pivot = monthly_climate.pivot_table(\n",
    "    index=['state', 'year'],\n",
    "    columns='month',\n",
    "    values=['average_temp', 'N0', 'D0', 'D1', 'D2', 'D3', 'D4', 'W0', 'W1', 'W2', 'W3', 'W4']\n",
    ")\n",
    "# Flatten the multi-level columns (concatenate feature and month)\n",
    "climate_pivot.columns = [f\"{col[0]}_{col[1]}\" for col in climate_pivot.columns]\n",
    "climate_pivot = climate_pivot.reset_index()\n",
    "# Save the pivoted dataset\n",
    "climate_pivot.to_csv('climate_pivot.csv')\n",
    "\n",
    "# MERGE PIVOTED DATASET WITH CROP DATA\n",
    "model_data = pandas.merge(\n",
    "    climate_pivot,\n",
    "    crop_data[['state', 'year', 'yield']],\n",
    "    on=['state','year'],\n",
    "    how='inner'\n",
    ")\n",
    "# Encode the state and year data as categorical columns\n",
    "model_data = pandas.get_dummies(model_data, columns=['state'], prefix='state')\n",
    "model_data = pandas.get_dummies(model_data, columns=['year'], prefix='year')\n",
    "# Save the finalized dataset\n",
    "model_data.to_csv('model_data.csv')\n",
    "\n",
    "# SPLIT DATA INTO FEATURES AND TARGETS\n",
    "x = model_data.drop(columns=['yield'])\n",
    "y = model_data['yield']\n",
    "\n",
    "# SPLIT DATA INTO TRAIN AND TEST SETS\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# STANDARDIZE SCALE OF DRY/WET AND AVERAGE TEMPERATURE DATA\n",
    "scaler = StandardScaler()\n",
    "# Fit and transform the training set\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "# Transform resulting array back to a dataframe with column names\n",
    "x_train_scaled = pandas.DataFrame(x_train_scaled, columns=x_train.columns)\n",
    "x_test_scaled = pandas.DataFrame(x_test_scaled, columns=x_test.columns)\n",
    "# Save the scaler\n",
    "joblib.dump(scaler,'scaler.pkl')\n",
    "\n",
    "# APPLY POLYNOMIAL FEATURES FOR FEATURE INTERACTION\n",
    "poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "# Fit and transform the training set\n",
    "x_train_poly = poly.fit_transform(x_train_scaled)\n",
    "x_test_poly = poly.transform(x_test_scaled)\n",
    "# Transform resulting array back to a dataframe with column names\n",
    "poly_feature_names = poly.get_feature_names_out(x_train.columns)\n",
    "x_train_poly = pandas.DataFrame(x_train_poly, columns=poly_feature_names)\n",
    "x_test_poly = pandas.DataFrame(x_test_poly, columns=poly_feature_names)\n",
    "# Save the polynomial feature transformer\n",
    "joblib.dump(poly, 'poly.pkl')\n",
    "\n",
    "# Print message upon completion\n",
    "print(f\"Data loading and preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec9bbb-aa9e-47f7-a1cc-3bcd2a0972a9",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d782d4c9-adcf-47d4-92ec-8292888970c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization code for EDA has been commented out to reduce clutter\n",
    "# See \"Visualization\" cell for the resultant plots\n",
    "\n",
    "## TEMPERATURE TREND BY YEAR\n",
    "# Plot displayed elsewhere after retrieval\n",
    "#average_temp_by_year = temp_data.groupby('year')['average_temp'].mean()\n",
    "#pyplot.plot(average_temp_by_year)\n",
    "#pyplot.title(\"Average Temperature Over Time\")\n",
    "#pyplot.xlabel(\"Year\")\n",
    "#pyplot.ylabel(\"Temperature\")\n",
    "#pyplot.savefig('temp_trend.png')\n",
    "#pyplot.show()\n",
    "\n",
    "## YIELD TREND BY YEAR\n",
    "# Plot displayed elsewhere after retrieval\n",
    "#average_yield_by_year = crop_data.groupby('year')['yield'].mean()\n",
    "#pyplot.plot(average_yield_by_year)\n",
    "#pyplot.title(\"Average Yield Over Time\")\n",
    "#pyplot.xlabel(\"Year\")\n",
    "#pyplot.ylabel(\"Yield (bushels/acre)\")\n",
    "#pyplot.savefig('yield_trend.png')\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1dad28-0f3a-4c26-b0ca-19d453ca0d72",
   "metadata": {},
   "source": [
    "### Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb33af2f-8ce5-43cc-b694-c6324831fe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 18.318581252896195\n",
      "R-Squared: 0.6444141987026155\n",
      "Model training is complete.\n"
     ]
    }
   ],
   "source": [
    "## HYPERPARAMETER TUNING USING CROSS-VALIDATION\n",
    "## Commented out after retrieving necessary parameters\n",
    "#param_grid = {\n",
    "#    'n_estimators': [50, 100, 200], # Number of trees\n",
    "#    'max_depth': [10, 20, None],\n",
    "#    'min_samples_split': [2, 5, 10],\n",
    "#    'min_samples_leaf': [1, 2, 4],\n",
    "#    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#    'bootstrap': [True, False]\n",
    "#}\n",
    "## Initialize Random Forest model\n",
    "#rf_model = RandomForestRegressor(random_state=42)\n",
    "## Initialize GridSearchCV with cross-validation\n",
    "#grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,\n",
    "#                           cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
    "## Perform grid search on training data\n",
    "#grid_search.fit(x_train_scaled, y_train)\n",
    "## Print best parameters\n",
    "#print(\"Best hyperparameters found: \", grid_search.best_params_)\n",
    "\n",
    "# INITIALIZE RANDOM FOREST MODEL WITH BEST PARAMETERS\n",
    "rf_model = RandomForestRegressor(\n",
    "    bootstrap=True,\n",
    "    max_depth=20,\n",
    "    max_features=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# TRAIN RANDOM FOREST MODEL\n",
    "rf_model.fit(x_train_poly, y_train)\n",
    "y_pred = rf_model.predict(x_test_poly)\n",
    "\n",
    "# EVALUATE MODEL WITH STANDARD METRICS\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R-Squared: {r2}\")\n",
    "\n",
    "## ACTUAL VS PREDICTED YIELD VISUALIZATION\n",
    "# Plot displayed elsewhere after retrieval\n",
    "#pyplot.scatter(y_test, y_pred)\n",
    "#pyplot.xlabel('Actual Yield')\n",
    "#pyplot.ylabel('Predicted Yield')\n",
    "#pyplot.title('Actual vs Predicted Yield')\n",
    "#pyplot.savefig('actual_vs_predicted.png')\n",
    "#pyplot.show()\n",
    "\n",
    "# CONDUCT FEATURE IMPORTANCE ANALYSIS\n",
    "importances = rf_model.feature_importances_\n",
    "sorted_indices = importances.argsort()[::-1]\n",
    "# Save the feature importance to a file\n",
    "polynomial_feature_importance = pandas.DataFrame({\n",
    "    'Feature': [poly_feature_names[i] for i in sorted_indices],\n",
    "    'Importance': [importances[i] for i in sorted_indices]\n",
    "})\n",
    "polynomial_feature_importance.to_csv('feature_importance.csv')\n",
    "\n",
    "## FEATURE IMPORTANCE VISUALIZATION\n",
    "# Plot displayed elsewhere after retrieval\n",
    "#importance_dataframe = pandas.read_csv('feature_importance.csv')\n",
    "#importance_dataframe = importance_dataframe[['Feature', 'Importance']]\n",
    "#importance_dataframe = importance_dataframe.sort_values(by='Importance', ascending=False)\n",
    "#top_20_features = importance_dataframe.head(20)\n",
    "#pyplot.figure(figsize=(10, 6))\n",
    "#seaborn.barplot(x='Importance', y='Feature', data=top_20_features)\n",
    "#pyplot.title(\"Feature Importance in Predicting Crop Yield\")\n",
    "#pyplot.xlabel(\"Importance\")\n",
    "#pyplot.ylabel(\"Feature\")\n",
    "#pyplot.savefig(\"feature_plot.png\")\n",
    "#pyplot.show()\n",
    "\n",
    "# SAVE THE TRAINED MODEL\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "\n",
    "# Print message upon completion\n",
    "print(f\"Model training is complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ee77c-0f34-4efc-a66f-f284db23e8f4",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00c12b-9ee1-48a6-9d6a-ee9adf109820",
   "metadata": {},
   "source": [
    "![](temp_trend.png)\n",
    "\n",
    "![](yield_trend.png)\n",
    "\n",
    "![](actual_vs_predicted.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5cea72-5602-4e65-9096-f5af447e24c0",
   "metadata": {},
   "source": [
    "### Yield Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c46fa6c-6d13-492d-ba78-4390e46d37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE MODEL AND SCALER\n",
    "rf_model = joblib.load('random_forest_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "poly = joblib.load('poly.pkl')\n",
    "\n",
    "# DEFINE PREDICTION FUNCTION\n",
    "def predict_yield(input_csv):\n",
    "    # Load the data for predictions\n",
    "    test_data = pandas.read_csv(input_csv)\n",
    "\n",
    "    # Ensure all required columns are present in the test data\n",
    "    required_columns = scaler.feature_names_in_\n",
    "    test_data = test_data.reindex(columns=required_columns, fill_value=0)\n",
    "\n",
    "    # Apply the same scaling used during training\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Apply polynomial feature transformation\n",
    "    test_data_poly = poly.transform(test_data_scaled)\n",
    "\n",
    "    # Convert back to dataframe with correct feature names\n",
    "    test_data_poly_dataframe = pandas.DataFrame(test_data_poly, columns=poly.get_feature_names_out(required_columns))\n",
    "\n",
    "    # Make predictions for each row in the test data\n",
    "    predicted_yields = rf_model.predict(test_data_poly_dataframe)\n",
    "\n",
    "    # Find the categorical state column for each row\n",
    "    state_columns = [col for col in test_data.columns if col.startswith('state_')]\n",
    "\n",
    "    # Print the predicted yields\n",
    "    for i, yield_val in enumerate (predicted_yields):\n",
    "        state_name = test_data.loc[i, state_columns].idxmax().replace('state_', '')\n",
    "        print(f\"Row {i+1}: The predicted yield in {state_name} is {yield_val:.2f} bushels per acre.\")\n",
    "\n",
    "#predict_yield('prediction_test_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
